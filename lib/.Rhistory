o<-rbind(o,matrix(unlist(oc[j]), ncol=2))
}
View(o)
plot(o)
plot(oc[[1]])
o<-matrix(unlist(oc[[1]]), ncol = 2)
sum <- sum(oc[[1]])
for (j in 2:length(oc)) {
sum <- sum + sum(oc[[j]])
o<-rbind(o,matrix(unlist(oc[j]), ncol=2))
plot(oc[[j]])
}
plot(oc[[1]])
o<-matrix(unlist(oc[[1]]), ncol = 2)
sum <- sum(oc[[1]])
for (j in 2:length(oc)) {
sum <- sum + sum(oc[[j]])
o<-rbind(o,matrix(unlist(oc[j]), ncol=2))
points(oc[[j]])
}
plot(o)
range(o)
range(o[,1])
range(o[,2])
plot(matrix(unlist(oc),ncol = 2))
b <- do.call(rbind.data.frame, oc)
plot(b)
plot(oc[[1]])
for (j in 2:length(oc)) {
sum <- sum + sum(oc[[j]])
o<-rbind(o,matrix(unlist(oc[j]), ncol=2))
points(oc[[j]])
}
b <- do.call(rbind.data.frame, oc)
View(b)
img <- resize(img2, 128, 128)
img <- thresh(img, w=50, h=50, offset=0.05)
oc <- ocontour(bwlabel(img))
b <- do.call(rbind.data.frame, oc)
plot(b)
img <- resize(img2, 128, 128)
img2 <- thresh(img, w=50, h=50, offset=0.05)
oc <- ocontour(bwlabel(img))
oc2 <- ocontour(bwlabel(img2))
b <- do.call(rbind.data.frame, oc)
b2 <- do.call(rbind.data.frame, oc2)
plot(b)
plot(b2)
plot(b)
plot(b2)
?thresh
length(oc)
length(oc2)
img <- readImage(file_paths[i])
img2 <- readImage(file_paths2[i])
img <- readImage(file_paths[i])
img2 <- readImage(file_paths2[i])
img_01 <- resize(img2, 128, 128)
img_02 <- thresh(img_01, w=50, h=50, offset=0.05)
oc <- ocontour(bwlabel(img_01))
oc2 <- ocontour(bwlabel(img_02))
b <- do.call(rbind.data.frame, oc)
b2 <- do.call(rbind.data.frame, oc2)
plot(b)
plot(b2)
length(oc)
length(oc2)
n_x <- 16
n_y <- 16
x_Bin <- seq(0, 1, length.out=n_x)
y_Bin <- seq(0, 1, length.out=n_y)
freq_location <- as.data.frame(table(factor(findInterval(b2[,1], n_x), levels=1:n_x),
factor(findInterval(b2[,2], n_y), levels=1:n_y)))
freq_location
findInterval(b2[,1], n_x
)
x_Bin <- seq(0, 128, length.out=n_x)
y_Bin <- seq(0, 128, length.out=n_y)
freq_location <- as.data.frame(table(factor(findInterval(b2[,1], n_x), levels=1:n_x),
factor(findInterval(b2[,2], n_y), levels=1:n_y)))
freq_location
x_Bin
img_01 <- resize(img2, 256, 256)
img_02 <- thresh(img_01, w=50, h=50, offset=0.05)
oc2 <- ocontour(bwlabel(img_02))
sum <- 0
for (j in 1:length(oc2)) {
sum <- sum + sum(oc2[[j]])
}
b2 <- do.call(rbind.data.frame, oc2)
n_x <- 16
n_y <- 16
x_Bin <- seq(0, 128, length.out=n_x)
y_Bin <- seq(0, 128, length.out=n_y)
x_Bin
16*16
x_Bin <- seq(0, 256, length.out=n_x)
y_Bin <- seq(0, 256, length.out=n_y)
x_Bin
length.out
n_x
n_x <- 15
n_y <- 15
x_Bin <- seq(0, 256, length.out=n_x)
y_Bin <- seq(0, 256, length.out=n_y)
x_Bin
?length
length(x_Bin)
n_x <- 16
n_y <- 16
x_Bin <- seq(0, 256, length.out=n_x)
256/16
nR <- 5
rBin <- seq(0, 1, length.out=nR)
rBin
n_x <- 16
n_x
seq(0, 256, length.out=n_x)
n_x <- 17
seq(0, 256, length.out=n_x)
n_y <- 17
x_Bin <- seq(0, 256, length.out=n_x)
y_Bin <- seq(0, 256, length.out=n_y)
freq_location <- as.data.frame(table(factor(findInterval(b2[,1], x_Bin), levels=1:n_x),
factor(findInterval(b2[,2], x_Bin), levels=1:n_y)))
freq_location
n_x <- 16
n_y <- 16
x_Bin <- seq(0, 256, length.out=n_x)
y_Bin <- seq(0, 256, length.out=n_y)
freq_location <- as.data.frame(table(factor(findInterval(b2[,1], x_Bin), levels=1:n_x),
factor(findInterval(b2[,2], x_Bin), levels=1:n_y)))
freq_location
ncol(mat)
nrow(mat)
location_feature <- as.numeric(freq_location$Freq)/(ncol(b2)*nrow(b2))
location_feature
gray_feature
mat <- imageData(img)
mat2 <- imageData(img2)
n <- 128
nBin <- seq(0, 1, length.out = n)
freq_gray <- as.data.frame(table(factor(findInterval(mat, nBin), levels = 1:n)))
gray_feature <- as.numeric(freq_gray$Freq)/(ncol(mat)*nrow(mat))
gray_feature
n <- 256
nBin <- seq(0, 1, length.out = n)
freq_gray <- as.data.frame(table(factor(findInterval(mat, nBin), levels = 1:n)))
gray_feature <- as.numeric(freq_gray$Freq)/(ncol(mat)*nrow(mat))
cor(freq_gray,freq_location)
freq_gray
cor(gray_feature,location_feature)
freq_location
install.packages("momocs")
install.packages("Momocs")
install.packages("Momocs")
library(Momocs)
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood, type = "l")
S <- 1000
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
post.N <- sample(N, S, replace = T, prob = post.p )
quantile(post.N, c(.025, .975))
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood, type = "l")
S <- 1000
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
post.N <- sample(N, S, replace = T, prob = post.p )
quantile(post.N, c(.025, .975))
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood, type = "l")
likelihood2 <- choose(N-100, 70) * choose(100, 20) / choose(N, 90)
plot(N, likelihood2, type = "l")
post.p <- likelihood/sum(likelihood)
plot(N, likelihood, type = "l")
lines(N, likelihood2, col=2)
plot(N, likelihood, type = "l")
lines(N, likelihood2, col=2)
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood, type = "l")
lines(N, likelihood2, col=2)
S <- 1000
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
post.N <- sample(N, S, replace = T, prob = post.p )
quantile(post.N, c(.025, .975))
plot(N, likelihood2, type = "l")
plot(N, likelihood/sum(likelihood), type = "l")
lines(N, likelihood2/sum(likelihood2), col=2)
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood/sum(likelihood), type = "l")
lines(N, likelihood2/sum(likelihood2), col=2)
S <- 1000
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
post.N <- sample(N, S, replace = T, prob = post.p )
quantile(post.N, c(.025, .975))
head(likelihood)
head(likelihood2)
head(likelihood/sum(likelihood))
head(likelihood2/sum(likelihood2))
library("NLP")
library("tm")
setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj4-team-14/output")
attach("CleanData.RData")
setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj4-team-14/lib")
source("p.function.R", local = T)
source("title.test.R", local = T)
final.j <- matrix(NA, nrow = 10, ncol = 14)
for (j in 1:14) {
df <- trans.data(j)
for(i in 1:10) {
final.j[i, j] <- acc.test(df, "j")
}
}
acc.mean.j <- apply(final.j, 2, mean)
acc.mean.j
acc.sd.j <- apply(final.j, 2, sd)
acc.sd.j
mean(acc.mean.j)
mean(acc.sd.j)
sd(acc.mean.j)
sd(acc.sd.j)
setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj4-team-14/output")
output.j <- rbind(final.j, acc.mean.j, acc.sd.j)
write.csv(output.j, file = "Journal.accuracy.result.csv")
final.p <- matrix(NA, nrow = 10, ncol = 14)
for (j in 1:14) {
df <- trans.data(j)
for(i in 1:10) {
final.p[i, j] <- acc.test(df, "p")
}
}
acc.mean.p <- apply(final.p, 2, mean)
acc.mean.p
acc.sd.p <- apply(final.p, 2, sd)
acc.sd.p
mean(acc.mean.p)
sd(acc.mean.p)
mean(acc.sd.p)
sd(acc.sd.p  )
output.p <- rbind(final.p, acc.mean.p, acc.sd.p)
write.csv(output.p, file = "Paper.accuracy.result.csv")
k=8
j=8
df <- trans.data(j)
index <- split_data(df)
train <- df[index, ]
test <- df[-index, ]
j=1
df <- trans.data(j)
index <- split_data(df)
train <- df[index, ]
test <- df[-index, ]
union(df$clusterid)
View(df)
unique(df$clusterid)
length(unique(df$clusterid))
acc.mean.p
N <- seq(170, 1200, 1)
likelihood2 <- choose(N-100, 70) * choose(100, 20) / choose(N, 90)
plot(N, likelihood3/sum(likelihood3), type = "l")
likelihood3 <- choose(100, 15) * choose(N-100, 70) / choose(N, 85)
plot(N, likelihood3/sum(likelihood3), type = "l")
post.p3 <- likelihood3/sum(likelihood3)
(E <- sum(N * post.p))
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
plot(N, likelihood/sum(likelihood), type = "l")
plot(N, likelihood3/sum(likelihood3), type = "l")
post.p3 <- likelihood3/sum(likelihood3)
(E <- sum(N * post.p))
(E <- sum(N * post.p3))
post.N <- sample(N, S, replace = T, prob = post.p3)
quantile(post.N, c(.025, .975))
post.N <- sample(N, S, replace = T, prob = post.p )
quantile(post.N, c(.025, .975))
quantile(post.p3, c(0.025, 0.975))
which(post.p3) == quantile(post.p3, 0.025)
which(post.p3 == quantile(post.p3, 0.025))
sum(post.p3[1:10])
sum(post.p3[1:100])
sum(post.p3[1:1000])
quantile(post.N, c(.025, .975))
342-170
sum(post.p3[1:170])
sum(post.p3[1:172])
sum(post.p3[1:178])
sum(post.p3[1:180])
N
N <- 3000
post.N <- sample(N, S, replace = T, prob = post.p3)
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood/sum(likelihood), type = "l")
S <- 1000
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
post.N <- sample(N, S, replace = T, prob = post.p )
quantile(post.N, c(.025, .975))
likelihood2 <- choose(N-100, 70) * choose(100, 20) / choose(N, 90)
plot(N, likelihood2/sum(likelihood2), type = "l")
lines(N, likelihood2, col=2)
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood/sum(likelihood), type = "l")
S <- 5000
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
post.N <- sample(N, S, replace = T, prob = post.p )
quantile(post.N, c(.025, .975))
likelihood2 <- choose(N-100, 70) * choose(100, 20) / choose(N, 90)
plot(N, likelihood2/sum(likelihood2), type = "l")
lines(N, likelihood2, col=2)
likelihood3 <- choose(100, 15) * choose(N-100, 70) / choose(N, 85)
plot(N, likelihood3/sum(likelihood3), type = "l")
post.p3 <- likelihood3/sum(likelihood3)
(E <- sum(N * post.p3))
post.N <- sample(N, S, replace = T, prob = post.p3)
quantile(post.N, c(.025, .975))
quantile(post.p3, c(0.025, 0.975))
sum(post.p3[1:180])
quantile(post.N, c(.025, .975))
415-170
sum(post.p3[1:245])
sum(post.p3[1:244])
sum(post.p3[1:242])
sum(post.p3[1:243])
N[254]
N[243]
quantile(post.N, c(.025, .975))
986-170
sum(post.p3[1:816])
sum(post.p3[1:817])
sum(post.p3[1:818])
sum(post.p3[1:820])
sum(post.p3[1:825])
sum(post.p3[1:824])
sum(post.p3[1:824])-sum(post.p3[1:243])
N[824]
?cumsum
N[which.min(abs(cumsum(post.p3)))]
N[which.min(abs(cumsum(post.p3) - 0.025))]
N[which.min(abs(cumsum(post.p3) - 0.975))]
quantile(post.N, c(.025, .975))
N[which.min(abs(cumsum(post.p) - 0.025))]
N[which.min(abs(cumsum(post.p) - 0.975))]
quantile(post.N, c(.025, .975))
N[which.min(abs(cumsum(post.p) - 0.025))]
N[which.min(abs(cumsum(post.p) - 0.975))]
N <- seq(170, 1200, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood/sum(likelihood), type = "l")
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
N[which.min(abs(cumsum(post.p) - 0.025))]
N[which.min(abs(cumsum(post.p) - 0.975))]
N <- seq(170, 2000, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood/sum(likelihood), type = "l")
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
N[which.min(abs(cumsum(post.p) - 0.025))]
N[which.min(abs(cumsum(post.p) - 0.975))]
N <- seq(170, 1700, 1)
likelihood <- choose(19+70, 19) * choose(N-20-70, 80) / choose(N, 100)
plot(N, likelihood/sum(likelihood), type = "l")
post.p <- likelihood/sum(likelihood)
(E <- sum(N * post.p))
N[which.min(abs(cumsum(post.p) - 0.025))]
N[which.min(abs(cumsum(post.p) - 0.975))]
likelihood2 <- choose(N-100, 70) * choose(100, 20) / choose(N, 90)
plot(N, likelihood2/sum(likelihood2), type = "l")
likelihood3 <- choose(100, 15) * choose(N-100, 70) / choose(N, 85)
plot(N, likelihood3/sum(likelihood3), type = "l")
post.p3 <- likelihood3/sum(likelihood3)
(E <- sum(N * post.p3))
N[which.min(abs(cumsum(post.p3) - 0.025))]
N[which.min(abs(cumsum(post.p3) - 0.975))]
t <- 0:5
t
choose(1+t,1)
choose(5+t,5)
?dbeta
dbeta(1,t+1,16)
dbeta(2,t+1,16)
?dbeta
pnorm(0)
dbeta(t+1,16)
dbeta(1,1,1)
dbeta(1,2,1)
dbeta(1,3,1)
dbeta(1,3,2)
dbeta(1,3,1)
dbeta(1,3,3)
x <- seq(0, 1, length = 21)
dbeta(x, 1, 1)
dbeta(0.5,1,1)
phi1 <- runif(1)
phi2 <- runif(1)
phi1
phi2
dbeta(phi1,t+1,16)
dbeta(phi2,6-t,71)
likelihood4 <- sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * dbeta(phi1,t+1,16) * dbeta(phi2,6-t,71))
dhyper(15+t, 100, N-100, 90)
index <- matrix(N, ncol = 1)
s <- function(N) { sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * dbeta(phi1,t+1,16) * dbeta(phi2,6-t,71)) }
s(N[1])
s(N[2])
likelihood4 <- s(N)
likelihood4 <- apply(index, 1, s)
plot(N, likelihood4, type = "l")
post.p4 <- likelihood4/sum(likelihood4)
(E <- sum(N * post.p4))
N[which.min(abs(cumsum(post.p4) - 0.025))]
N[which.min(abs(cumsum(post.p4) - 0.975))]
t <- 0:5
phi1 <- runif(1)
phi2 <- runif(1)
index <- matrix(N, ncol = 1)
s <- function(N) { sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * dbeta(phi1,t+1,16) * dbeta(phi2,6-t,71)) }
likelihood4 <- apply(index, 1, s)
plot(N, likelihood4, type = "l")
post.p4 <- likelihood4/sum(likelihood4)
(E <- sum(N * post.p4))
N[which.min(abs(cumsum(post.p4) - 0.025))]
N[which.min(abs(cumsum(post.p4) - 0.975))]
t <- 0:5
phi1 <- runif(1)
phi2 <- runif(1)
index <- matrix(N, ncol = 1)
s <- function(N) { sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * dbeta(phi1,t+1,16) * dbeta(phi2,6-t,71)) }
likelihood4 <- apply(index, 1, s)
plot(N, likelihood4, type = "l")
post.p4 <- likelihood4/sum(likelihood4)
(E <- sum(N * post.p4))
N[which.min(abs(cumsum(post.p4) - 0.025))]
N[which.min(abs(cumsum(post.p4) - 0.975))]
t <- 0:5
phi1 <- runif(1)
phi2 <- runif(1)
index <- matrix(N, ncol = 1)
s <- function(N) { sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * dbeta(phi1,t+1,16) * dbeta(phi2,6-t,71)) }
likelihood4 <- apply(index, 1, s)
plot(N, likelihood4, type = "l")
post.p4 <- likelihood4/sum(likelihood4)
(E <- sum(N * post.p4))
N[which.min(abs(cumsum(post.p4) - 0.025))]
N[which.min(abs(cumsum(post.p4) - 0.975))]
t <- 0:5
phi1 <- runif(1)
phi2 <- runif(1)
index <- matrix(N, ncol = 1)
s <- function(N) { sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * dbeta(phi1,t+1,16) * dbeta(phi2,6-t,71)) }
likelihood4 <- apply(index, 1, s)
plot(N, likelihood4, type = "l")
post.p4 <- likelihood4/sum(likelihood4)
(E <- sum(N * post.p4))
N[which.min(abs(cumsum(post.p4) - 0.025))]
N[which.min(abs(cumsum(post.p4) - 0.975))]
t <- 0:5
phi1 <- runif(1)
phi2 <- runif(1)
index <- matrix(N, ncol = 1)
s <- function(N) { sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * dbeta(phi1,t+1,16) * dbeta(phi2,6-t,71)) }
likelihood4 <- apply(index, 1, s)
plot(N, likelihood4, type = "l")
post.p4 <- likelihood4/sum(likelihood4)
(E <- sum(N * post.p4))
N[which.min(abs(cumsum(post.p4) - 0.025))]
N[which.min(abs(cumsum(post.p4) - 0.975))]
dbeta
?dbeta
beta(1,1)
beta(1,2)
t <- 0:5
index <- matrix(N, ncol = 1)
s <- function(N) { sum(dhyper(15+t, 100, N-100, 90) * choose(15+t, 15) * choose(75-t, 70) * beta(t+1,16) * beta(6-t,71)) }
likelihood4 <- apply(index, 1, s)
plot(N, likelihood4, type = "l")
post.p4 <- likelihood4/sum(likelihood4)
(E <- sum(N * post.p4))
N[which.min(abs(cumsum(post.p4) - 0.025))]
N[which.min(abs(cumsum(post.p4) - 0.975))]
7/26
24/65
13/20-24/65
(13/20-24/65)*65*4
65*4
24/65
73/260-35/82
1-0.65-24/65
payoff <- c(1,2,3,10)
prob <- c(0.35, 0.24, 0.175, 0.235)
payoff * prob
sum(payoff * prob)
sum(payoff * c(0.35, 0.7*0.5^2, 0.7*0.5^3, 0.7*0.5^3))
sum(payoff * c(0.24, 0.3*0.8*0.2, 0.3*0.8*0.2^2, 0.3*0.2^3))
sum(payoff * c(0.5, 0.5^2, 0.5^3, 0.5^3))
sum(payoff * c(0.8, 0.8*0.2, 0.8*0.2^2, 0.2^3))
2.625*0.7+1.296*0.3
2.625*0.7+1.296*0.3-3.705
setwd("~/Desktop/sem 2/Applied data science/Spr2017-proj4-team-14/lib")
attach("~/Desktop/sem 2/Applied data science/Spr2017-proj4-team-14/output/CleanData.RData")
