co <- cbind(co, d[[i]][[3]])
}
co <- "Start"
cbind(co,d[[1]][[3]])
co <- "Start"
co <- "Start"
rbind(co,d[[1]][[3]])
co <- matrix(c("Start", "Start"), nrow = 1)
cbind(co,d[[1]][[3]])
co <- NA
c(co,d[[1]][[3]])
co <- NULL
c(co,d[[1]][[3]])
co <- NULL
for(i in 1:n){
co <- c(co, d[[i]][[3]])
}
length(co)
unique(co)
co <- unique(co)
m <- length(co)
AP <- matrix(rep(0,n*m), nrow = n)
s <- d1[[1]][[3]]
s
co[1]
c <- co[1]
c %in% s
co <- unique(co)
m <- length(co)
AP <- matrix(rep(0,n*m), nrow = n)
for(i in 1:m){
for( j in 1:n){
if(co[i] %in% d[[j]][[3]]){
AP[j,i] <- 1
}
}
}
View(AP)
dim(AP)
co <- unique(co)
m <- length(co)
AA <- matrix(rep(0, m*m), nrow = m)
for(i in 1:m){
for(j in 1:m){
for(k in 1:n){
if(co[i] %in% d[[k]][[3]] & co[j] %in% d[[k]][[3]]){
AA[i,j] <- 1
break
}
}
}
}
M1 <- cbind(P, AP)
M2 <- cbind(t(AP), AA)
M <- rbind(M1,M2)
dim(M)
View(M)
require("../lib/M.rmd")
require("../lib/M.Rmd")
setwd("~/GitHub/Spr2017-proj4-team-14/doc")
require("../lib/M.Rmd")
source("../lib/M.Rmd")
load("../ouput/CleanData.RData")
load("../output/CleanData.RData")
source("../lib/M.Rmd")
source("../lib/M.Rmd")
source("../lib/M.R")
source("../lib/M.R")
load("../output/CleanData.RData")
n <- length(data_list)
?save
names(data_list)
M <- list(NA, length = n)
M <- data_list
source("../lib/M.R")
load("../output/CleanData.RData")
n <- length(data_list)
M <- data_list
for(i in 1:n){
M[[i]] <- M6(data_list[[i]])
}
i <-3
cat( "Dataset NO.", i, " Finished")
cat( "Dataset NO.", i, " Finished", sep = "")
for(i in 1:n){
M[[i]] <- M6(data_list[[i]])
cat( "Dataset NO.", i, " Finished", sep = "")
}
cat(i, " Finished ", n-i, " Left", sep = "")
cat(i, " Completed ", n-i, " Left", sep = "")
d <- data_list[[1]]
n <- length(d)
label <- vector(NA, length = n)
label <- vector("numeric", length = n)
for(i in 1:n){
label[i] <- d[[i]][[1]]
}
d[[1:2]]
d[[1]]
d[[4]]
for(i in 1:K){
M[[i]] <- M6(data_list[[i]])
cat(i, " Completed ", K-i, " Left", sep = "")
}
source("../lib/M.R")
load("../output/CleanData.RData")
K <- length(data_list)
M <- data_list
for(i in 1:K){
M[[i]] <- M6(data_list[[i]])
cat(i, " Completed ", K-i, " Left", sep = "")
}
save(M, file = "../output/M.RData")
source("../lib/M.R")
load("../output/CleanData.RData")
K <- length(data_list)
d <- data_list[[1]]
n <- length(d)
label <- vector("numeric", length = n) #### Save true assignments.
for(i in 1:n){
label[i] <- d[[i]][[1]]
}
head(label)
k <- unique(label)
k
load("../output/M.RData")
m <- M[[1]]
m
dim(m)
m
View(m)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
setwd("~/Dropbox/Project4_WhoIsWho/doc")
# here replace it with your own path or manually set it in RStudio
# to where this rmd file is located
AKumar <- data.frame(scan("~/Dropbox/Project4_WhoIsWho/data/nameset/AKumar.txt",
what = list(Coauthor = "", Paper = "", Journal = ""),
sep=">", quiet=TRUE),stringsAsFactors=FALSE)
# This need to be modified for different name set
# extract canonical author id befor "_"
AKumar$AuthorID <- sub("_.*","",AKumar$Coauthor)
# extract paper number under same author between "_" and first whitespace
AKumar$PaperNO <- sub(".*_(\\w*)\\s.*", "\\1", AKumar$Coauthor)
# delete "<" in AKumar$Coauthor, you may need to further process the coauthor
# term depending on the method you are using
AKumar$Coauthor <- gsub("<","",sub("^.*?\\s","", AKumar$Coauthor))
# delete "<" in AKumar$Paper
AKumar$Paper <- gsub("<","",AKumar$Paper)
# add PaperID for furthur use, you may want to combine all the nameset files and
# then assign the unique ID for all the citations
AKumar$PaperID <- rownames(AKumar)
AKumar <- data.frame(scan("../data/nameset/AKumar.txt",
what = list(Coauthor = "", Paper = "", Journal = ""),
sep=">", quiet=TRUE),stringsAsFactors=FALSE)
AKumar$AuthorID <- sub("_.*","",AKumar$Coauthor)
AKumar <- data.frame(scan("../data/nameset/AKumar.txt",
what = list(Coauthor = "", Paper = "", Journal = ""),
sep=">", quiet=TRUE),stringsAsFactors=FALSE)
# This need to be modified for different name set
# extract canonical author id befor "_"
AKumar$AuthorID <- sub("_.*","",AKumar$Coauthor)
# extract paper number under same author between "_" and first whitespace
AKumar$PaperNO <- sub(".*_(\\w*)\\s.*", "\\1", AKumar$Coauthor)
# delete "<" in AKumar$Coauthor, you may need to further process the coauthor
# term depending on the method you are using
AKumar$Coauthor <- gsub("<","",sub("^.*?\\s","", AKumar$Coauthor))
# delete "<" in AKumar$Paper
AKumar$Paper <- gsub("<","",AKumar$Paper)
# add PaperID for furthur use, you may want to combine all the nameset files and
# then assign the unique ID for all the citations
AKumar$PaperID <- rownames(AKumar)
it_train <- itoken(AKumar$Paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
ids = AKumar$PaperID,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vocab
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
d[[1]][[5]]
M.Matrix <- M
names(M.Matrix) <- names(data_list)
names(M.Matrix)
names(M.Matrix) <- names(data_list)
save(M.Matrix, file = "../output/M.RData")
AKumar$Paper
d <- data_list[[2]]
m <- M[[2]]
d <- data_list[[2]]
M <- M.Matrix[[2]]
paper <- vector("character", length = n)
for(i in 1:n){
paper[i] <- d[[i]][[5]]
}
d <- data_list[[2]]
M <- M.Matrix[[2]]
n <- length(d) #### Number of publications
paper <- vector("character", length = n)
for(i in 1:n){
paper[i] <- d[[i]][[5]]
}
label <- vector("numeric", length = n) #### Save true assignments.
for(i in 1:n){
label[i] <- d[[i]][[1]]
}
k <- length(unique(label)) #### Number of clusters.
identical(paper, AKumar$Paper)
paper[1]
AKumar$Paper[1]
paper[1] %in%% AKumar$Paper
paper[1] %in% AKumar$Paper
s <- AKumar$Paper
it_train <- itoken(paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
train.data <- fit_transform(dtm_train, tfidf)
train.data
data.train[1,]
train.data[1,]
train.data <- as.matrix(fit_transform(dtm_train, tfidf))
View(train.data)
dim(train.data)
M <- M.Matrix[[2]]
b <- M%*%M
sum(b>2)
b <- b[1:244,1:244]
sum(b>2)
z <- M^2
z == M%*%M
sum(z != M%*%M)
x <- M^2
z <- M%*%M
require("pacman")
source("../lib/M.R")
load("../output/CleanData.RData")
load("../output/M.RData")
d <- data_list[[2]]
M <- M.Matrix[[2]]
n <- length(d) #### Number of publications
paper <- vector("character", length = n)
for(i in 1:n){
paper[i] <- d[[i]][[5]]
}
it_train <- itoken(paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
it_train <- itoken(paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
require("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
source("../lib/M.R")
load("../output/CleanData.RData")
load("../output/M.RData")
d <- data_list[[2]]
M <- M.Matrix[[2]]
n <- length(d) #### Number of publications
paper <- vector("character", length = n)
for(i in 1:n){
paper[i] <- d[[i]][[5]]
}
it_train <- itoken(paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
train.data <- as.matrix(fit_transform(dtm_train, tfidf))
label <- vector("numeric", length = n) #### Save true assignments.
for(i in 1:n){
label[i] <- d[[i]][[1]]
}
k <- length(unique(label)) #### Number of clusters.
require("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
source("../lib/M.R")
load("../output/CleanData.RData")
load("../output/M.RData")
d <- data_list[[2]]
M <- M.Matrix[[2]]
n <- length(d) #### Number of publications
paper <- vector("character", length = n)
for(i in 1:n){
paper[i] <- d[[i]][[5]]
}
it_train <- itoken(paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
train.data <- as.matrix(fit_transform(dtm_train, tfidf)) #### Get train data features.
label <- vector("numeric", length = n) #### Save true assignments.
for(i in 1:n){
label[i] <- d[[i]][[1]]
}
k <- length(unique(label)) #### Number of clusters.
m <- M
d <- train.data
n <- nrow(d) #### Number of publications
m <- M
t <- 3
for(i in 1:t){
m <- m%*%M
}
m <- m[1:n, 1:n]
View(m)
sum(m == 0)
244*244
t <- 5
n <- nrow(d) #### Number of publications
m <- M
for(i in 1:t){
m <- m%*%M
}
m <- m[1:n, 1:n]
sum(m == 0)
View(M)
t <- 4
n <- nrow(d) #### Number of publications
m <- M
for(i in 1:t){
m <- m%*%M
}
m <- m[1:n, 1:n]
l <- vector("numeric", n) #### Store train_labels
l1 <- vector("numeric", n) #### For comparison
l2 <- vector("numeric", n)
sum(m == 0)
244*244
y <- list(length = k)
?list
y <- list()
a <- c(1,2,3)
b <- c(4,5,6)
mean(a,b)
sum(a,b)
y <- matrix(NA, nrow = k, ncol = ncol(d))
d <- data_list[[2]]
M <- M.Matrix[[2]]
n <- length(d) #### Number of publications
paper <- vector("character", length = n)
for(i in 1:n){
paper[i] <- d[[i]][[5]]
}
it_train <- itoken(paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
train.data <- as.matrix(fit_transform(dtm_train, tfidf)) #### Get train data features.
label <- vector("numeric", length = n) #### Save true assignments.
for(i in 1:n){
label[i] <- d[[i]][[1]]
}
k <- length(unique(label)) #### Number of clusters.
d <- train.data
n <- nrow(d) #### Number of publications
m <- M
t <-3
m <- M
for(i in 1:t){
m <- m%*%M
}
m <- m[1:n, 1:n]
l <- vector("numeric", n) #### Store train_labels
l1 <- vector("numeric", n) #### For comparison
l2 <- vector("numeric", n)
y <- matrix(NA, nrow = k, ncol = ncol(d))
q <- d[1:3,]
apply(sum,q,2)
?apply
apply
apply(q,sum,2)
apply(q,2,sum)
q <- apply(q,2,sum)
dim(q)
length(q)
A <- matrix(NA, nrow = ncol(d), ncol = ncol(d))
diag(A) <- rep(1,nrow(A))
View(A)
A <- matrix(0, nrow = ncol(d), ncol = ncol(d))
View(A)
y <- matrix(0, nrow = k, ncol = ncol(d))
A <- matrix(0, nrow = ncol(d), ncol = ncol(d))
diag(A) <- rep(1,nrow(A))
D <- function(a,b,C){
s <- 1-(t(a) %*% C %*% b)/ sqrt(t(a) %*% C %*% a)/ sqrt(t(b) %*% C %*% b)
return(s)
}
c <- matrix(rep(0,4))
a <- c(1,2)
diag(c) <- c(2,2)
c
c <- matrix(rep(0,4), nrow = 2)
diag(c) <- c(2,2)
t(a) %*% c %*% a
t(a) %*% c %*% a /5
1- t(a) %*% c %*% a /5
c <- 0.7^t
n <- nrow(d) #### Number of publications
m.matrix <- M
for(i in 1:t){
m.matrix <- m.matrix%*%M
}
m.matrix <- m.matrix[1:n, 1:n]
c <- 0.7^t
label <- vector("numeric", n) #### Store train_labels
label1 <- vector("numeric", n) #### For comparison
label2 <- vector("numeric", n)
y <- matrix(0, nrow = k, ncol = ncol(d))
A <- matrix(0, nrow = ncol(d), ncol = ncol(d))
diag(A) <- rep(1,nrow(A))
D <- function(a,b,C){
s <- 1 - as.numeric( (t(a) %*% C %*% b)/ sqrt(t(a) %*% C %*% a)/ sqrt(t(b) %*% C %*% b) )
return(s)
}
for(i in 1:k){
y[i,] <- apply(d[(label2 == i),], 2, sum)
}
require("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
source("../lib/M.R")
load("../output/CleanData.RData")
load("../output/M.RData")
d <- data_list[[2]]
M <- M.Matrix[[2]]
n <- length(d) #### Number of publications
paper <- vector("character", length = n)
for(i in 1:n){
paper[i] <- d[[i]][[5]]
}
it_train <- itoken(paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
train.data <- as.matrix(fit_transform(dtm_train, tfidf)) #### Get train data features.
label <- vector("numeric", length = n) #### Save true assignments.
for(i in 1:n){
label[i] <- d[[i]][[1]]
}
k <- length(unique(label)) #### Number of clusters.
d <- train.data
n <- nrow(d) #### Number of publications
m.matrix <- M
for(i in 1:t){
m.matrix <- m.matrix%*%M
}
t <- 3
for(i in 1:t){
m.matrix <- m.matrix%*%M
}
m.matrix <- m.matrix[1:n, 1:n]
w <- 0.7^t
label2 <- vector("numeric", n) #### Store train_labels
label1 <- vector("numeric", n) #### For comparison
y <- matrix(0, nrow = k, ncol = ncol(d))
A <- matrix(0, nrow = ncol(d), ncol = ncol(d))
diag(A) <- rep(1,nrow(A))
D <- function(a,b,C){
s <- 1 - as.numeric( (t(a) %*% C %*% b)/ sqrt(t(a) %*% C %*% a)/ sqrt(t(b) %*% C %*% b) )
return(s)
}
for(i in 1:k){
y[i,] <- apply(d[(label2 == i),], 2, sum)/sum(label2 == i)
}
diag(A) <- rep(1,nrow(A))
